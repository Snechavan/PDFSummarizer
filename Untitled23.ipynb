{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+mc+HY59RMtDbrV4Emr4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snechavan/PDFSummarizer/blob/main/Untitled23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn83JTKBaEvn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install fpdf\n",
        "!pip install gensim\n",
        "!pip install PyPDF2  # Install PyPDF2 for PDF handling\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import nltk\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from google.colab import files\n",
        "from fpdf import FPDF  # For saving summary as PDF\n",
        "from PyPDF2 import PdfReader  # For extracting text from PDFs\n",
        "\n",
        "# Step 3: Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 4: Load models for summarization\n",
        "abstractive_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")  # BART for abstractive summarization\n",
        "\n",
        "# Step 5: Define summarization function with better chunking based on tokens\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "def abstractive_summary(text):\n",
        "    # Tokenize text to ensure chunks are within the token limit of the BART model\n",
        "    max_tokens = 1024  # BART model max token limit\n",
        "\n",
        "    tokens = tokenizer.encode(text, truncation=False)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # If text exceeds max token limit, break it into smaller chunks\n",
        "    if num_tokens > max_tokens:\n",
        "        text_chunks = [tokens[i:i + max_tokens] for i in range(0, num_tokens, max_tokens)]\n",
        "        summaries = []\n",
        "        for chunk in text_chunks:\n",
        "            chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
        "            chunk_summary = abstractive_summarizer(chunk_text, min_length=30, max_length=200)\n",
        "            summaries.append(chunk_summary[0]['summary_text'])\n",
        "        return \" \".join(summaries)\n",
        "    else:\n",
        "        summary = abstractive_summarizer(text, min_length=30, max_length=200)\n",
        "        return summary[0]['summary_text']\n",
        "\n",
        "# Step 6: Functions to extract text from uploaded files\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    pdf_text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                pdf_text += text\n",
        "    return pdf_text\n",
        "\n",
        "def extract_text_from_txt(txt_path):\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Step 7: Summarize uploaded files and create new PDF with summary\n",
        "def summarize_uploaded_file(uploaded_files, method=\"abstractive\"):\n",
        "    for uploaded_file in uploaded_files:\n",
        "        file_path = uploaded_file\n",
        "        file_extension = uploaded_file.split(\".\")[-1]\n",
        "\n",
        "        if file_extension == \"pdf\":\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "        elif file_extension == \"txt\":\n",
        "            text = extract_text_from_txt(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file format: {file_extension}\")\n",
        "            return\n",
        "\n",
        "        # Ensure text was extracted\n",
        "        if len(text.strip()) == 0:\n",
        "            print(f\"No text extracted from {file_path}, skipping summarization.\")\n",
        "            continue\n",
        "\n",
        "        # Display the extracted text for debugging\n",
        "        print(f\"Extracted text from {file_path}:\\n{text[:500]}...\")  # Display the first 500 characters\n",
        "\n",
        "        if method == \"abstractive\":\n",
        "            summary = abstractive_summary(text)\n",
        "        else:\n",
        "            print(\"Invalid summarization method selected.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Summary for {file_path} ({method} summarization):\")\n",
        "        print(summary)\n",
        "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Step 8: Save summary as a new PDF\n",
        "        output_pdf_path = file_path.split(\".\")[0] + \"_summary.pdf\"\n",
        "        save_summary_as_pdf(summary, output_pdf_path)\n",
        "\n",
        "        # Trigger the download\n",
        "        files.download(output_pdf_path)  # Download the summary PDF\n",
        "\n",
        "# Step 9: Save summary to a PDF file with UTF-8 support\n",
        "def save_summary_as_pdf(summary, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Set font to a Unicode-compatible font (Arial Unicode MS or another Unicode font)\n",
        "    pdf.set_font(\"Arial\", size=12)  # You can change to a more suitable Unicode font if needed\n",
        "    pdf.multi_cell(0, 6, summary.encode('latin-1', 'replace').decode('latin-1'))  # Handle non-ASCII chars gracefully\n",
        "\n",
        "    pdf.output(output_pdf_path)\n",
        "\n",
        "# Step 10: Upload files\n",
        "uploaded = files.upload()\n",
        "uploaded_file_paths = list(uploaded.keys())\n",
        "\n",
        "# Step 11: Run the summarization function\n",
        "summarize_uploaded_file(uploaded_file_paths, method=\"abstractive\")\n"
      ]
    }
  ]
}