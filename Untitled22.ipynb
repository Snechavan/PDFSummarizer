{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+mc+HY59RMtDbrV4Emr4G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snechavan/PDFSummarizer/blob/main/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoOa6l2hYzjC",
        "outputId": "c0336297-f381-4d74-d128-4a3f7429069c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=094244a471cc194177abfed6068e6b4e43f9bd2ba93532760756d5b59dd0781c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install fpdf\n",
        "!pip install gensim\n",
        "!pip install PyPDF2  # Install PyPDF2 for PDF handling\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import nltk\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from google.colab import files\n",
        "from fpdf import FPDF  # For saving summary as PDF\n",
        "from PyPDF2 import PdfReader  # For extracting text from PDFs\n",
        "\n",
        "# Step 3: Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 4: Load models for summarization\n",
        "abstractive_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")  # BART for abstractive summarization\n",
        "\n",
        "# Step 5: Define summarization function with better chunking based on tokens\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "def abstractive_summary(text):\n",
        "    # Tokenize text to ensure chunks are within the token limit of the BART model\n",
        "    max_tokens = 1024  # BART model max token limit\n",
        "\n",
        "    tokens = tokenizer.encode(text, truncation=False)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # If text exceeds max token limit, break it into smaller chunks\n",
        "    if num_tokens > max_tokens:\n",
        "        text_chunks = [tokens[i:i + max_tokens] for i in range(0, num_tokens, max_tokens)]\n",
        "        summaries = []\n",
        "        for chunk in text_chunks:\n",
        "            chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
        "            chunk_summary = abstractive_summarizer(chunk_text, min_length=30, max_length=200)\n",
        "            summaries.append(chunk_summary[0]['summary_text'])\n",
        "        return \" \".join(summaries)\n",
        "    else:\n",
        "        summary = abstractive_summarizer(text, min_length=30, max_length=200)\n",
        "        return summary[0]['summary_text']\n",
        "\n",
        "# Step 6: Functions to extract text from uploaded files\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    pdf_text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                pdf_text += text\n",
        "    return pdf_text\n",
        "\n",
        "def extract_text_from_txt(txt_path):\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Step 7: Summarize uploaded files and create new PDF with summary\n",
        "def summarize_uploaded_file(uploaded_files, method=\"abstractive\"):\n",
        "    for uploaded_file in uploaded_files:\n",
        "        file_path = uploaded_file\n",
        "        file_extension = uploaded_file.split(\".\")[-1]\n",
        "\n",
        "        if file_extension == \"pdf\":\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "        elif file_extension == \"txt\":\n",
        "            text = extract_text_from_txt(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file format: {file_extension}\")\n",
        "            return\n",
        "\n",
        "        # Ensure text was extracted\n",
        "        if len(text.strip()) == 0:\n",
        "            print(f\"No text extracted from {file_path}, skipping summarization.\")\n",
        "            continue\n",
        "\n",
        "        # Display the extracted text for debugging\n",
        "        print(f\"Extracted text from {file_path}:\\n{text[:500]}...\")  # Display the first 500 characters\n",
        "\n",
        "        if method == \"abstractive\":\n",
        "            summary = abstractive_summary(text)\n",
        "        else:\n",
        "            print(\"Invalid summarization method selected.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Summary for {file_path} ({method} summarization):\")\n",
        "        print(summary)\n",
        "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
        "\n",
        "        # Step 8: Save summary as a new PDF\n",
        "        output_pdf_path = file_path.split(\".\")[0] + \"_summary.pdf\"\n",
        "        save_summary_as_pdf(summary, output_pdf_path)\n",
        "\n",
        "        # Trigger the download\n",
        "        files.download(output_pdf_path)  # Download the summary PDF\n",
        "\n",
        "# Step 9: Save summary to a PDF file with UTF-8 support\n",
        "def save_summary_as_pdf(summary, output_pdf_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Set font to a Unicode-compatible font (Arial Unicode MS or another Unicode font)\n",
        "    pdf.set_font(\"Arial\", size=12)  # You can change to a more suitable Unicode font if needed\n",
        "    pdf.multi_cell(0, 6, summary.encode('latin-1', 'replace').decode('latin-1'))  # Handle non-ASCII chars gracefully\n",
        "\n",
        "    pdf.output(output_pdf_path)\n",
        "\n",
        "# Step 10: Upload files\n",
        "uploaded = files.upload()\n",
        "uploaded_file_paths = list(uploaded.keys())\n",
        "\n",
        "# Step 11: Run the summarization function\n",
        "summarize_uploaded_file(uploaded_file_paths, method=\"abstractive\")\n"
      ]
    }
  ]
}